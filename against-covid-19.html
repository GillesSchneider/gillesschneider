<!DOCTYPE html>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<html lang="fr">

	<head>
		<title>AI AGAINST COVID-19</title>
		<meta charset="utf-8">
	  	<meta name="viewport" content="width=device-width, initial-scale=1">
	  	<link rel="stylesheet" href="dist/css/bootstrap.css">
		<link rel="stylesheet" href="dist/css/cadre.scss">
	  	<link rel="stylesheet" type="dist/css" href="main.css">
	  	<link rel="stylesheet" type="dist/css" href="timeline.css">
		<meta name="description" content="Élève ingénieur en informatique à Concordia University/IMT Atlantique, spécialisé en intelligence artificielle, data science, développement logiciel et algorithmique.">
  		<meta name="keywords" content="Computer Science, Healthcare, Concordia, IMT Atlantique">
		<meta name="author" content="Gilles Schneider">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css" integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	</head>
	<body>


		<header style="height:100%;">
		<div class="bg"></div>

			<div class="container" style="color:white; background:white;" >
				<div class="row" style="height: 20px;">
					<div class="col" style="background: var(--primary);"></div>
					<div class="col" style="background: var(--secondary);"></div>
					<div class="col" style="background: #b8cfe6;"></div>
				</div>


				<div class="row">


					<div class="col my-4" style="text-align:center;">

						 <h5 style="color:var(--dark); text-align: left;">
							Last update: June 13, 2021
							 <br>
							 	Author:
							 <br>
							 <a class="t-link" target="_blank" href="https://gillesschneider.github.io/me/index.html" style="color:var(--primary); text-align: left;">
									@gilles.schneider
							  </a>
							 <br>
							 	Co-author:
							 <br>
							  <a class="t-link" target="_blank" href="https://www.linkedin.com/in/hugo-kermabon/" style="color:var(--primary); text-align: left;">
									@hugo.kermabon
							  </a>

						</h5>



                        <h5 style="color:var(--dark); text-align: right;">
							May 31, 2021
							/
							Jun 14, 2021
						</h5>
						<h5 style="color:var(--dark); text-align: right;">
							Team: ConcordIA

						</h5>
						<h5 style="color:var(--dark); text-align: right;">
							Rank: TBA
						</h5>
						<a href="https://github.com/hkerma/against-covid-19-ConcordIA" target="_blank" class="fa fa-github" style="color:#6e79a9; float: right; font-size: 40px; width: 30px; text-align: center; text-decoration: none; border-radius: 50%;"></a>
						<br>
							<div class="divider-1"></div>
						<h1 class="t-intro"> AI AGAINST COVID19 </h1>
                        <h4 style="color: black; font-style: italic"> Screening X-ray images for COVID-19 Infections</h4>
						<p class="p-intro" >
                            Organized by: IEEE SIGHT MTL,
							VIP lab,
							DarwinAI.

						</p>
						<br>

						<div class = "t-tag-list">
								<span>Convolutional Neural Network</span><span>Image Classification</span><span>COVID-19</span><span>Chest X-Ray</span>
						</div>
						<div class="divider-1"></div>
						<!-- TODO: fix contact me -->

					</div>

				</div>

			</div>

		</header>

		<section>
			<div class="container" style="background: white;">



				<div class="row">

						<div class="col-md-6">

							<h4>1. Challenge</h4>
							<p class="t-paragraph">The coronavirus disease 2019 (COVID-19) pandemic, caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) virus, has generated an unprecedented global health crisis, with more than 2.7 million deaths worldwide.
								The challenge consists of designing robust machine learning algorithms to predict if the subjects of study are either COVID-19 positive or COVID-19 negative. See more <a class="t-link"  target="_blank" href="https://r7.ieee.org/montreal-sight/ai-against-covid-19/">here</a>.</p>

							<div class="divider-1"></div>
						</div>
						<div class="col-md">

								<h4>2. Motivations</h4>
									<p class="t-paragraph">
										The <b>SARS-CoV-2 2019 (COVID-19)</b> current infection or past infection can be respectively detected by a <b>viral test</b> and an <b>antibody test</b>. However, artificial intelligence
										could become handy to help researchers diagnose COVID-10 with X-ray images, accelerating the treatment of people infected and saving lives.
										I am highly concerned of improving well-being. Therefore, I picked this challenge.
									</p>

							<div class="divider-1"></div>
						</div>
				</div>
				<div class="row">
						<div class="col-md">
								<h4>3. COVIDx CXR-2</h4>
									<p class="t-paragraph">
                               			The <a class="t-link" target="_blank" href="https://www.kaggle.com/andyczhao/covidx-cxr2" >COVIDx CXR-2</a> dataset contains images of COVID positive and negative chest radiography images from  publicly available data sources: <b>covid-chestray-dataset</b>, etc.
										COVIDx CXR-2 is highly imbalanced. Indeed, around <b>86%</b> of the train set is <b>COVID-Positive CXRs (13793)</b>, thus only <b>14%</b> is <b>COVID-19 Negative CXRs (2158)</b>.
										It might be due to the <b>percent positive</b>, (percentage
										of all coronavirus tests performed that are actually positive) that is often low.
										For instance, a reasonable percent positive has to be below 5% according to the World Health Organization.
                            		</p>
									<br>
							<div class="divider-1"></div>

						</div>

				</div>


				<div class="row">

					<div class="col-md-6">

							<h4>4. Pre-processing</h4>
							<p class="t-paragraph">

								The images were resized to <b>240x240</b> and <b>normalized</b>. We trained on <b>RGB</b> CXRs (3 channels). We did an <b>histogram normalization</b> for each channel of the CXRs to make pixel distribution
								uniform. The normalized CXRs look darker (Fig. 5).
							</p>
							<div class="divider-1"></div>
					</div>

					<div class="col-md-3" style="text-align: center">
							<img style="width: 200px; height: 200px;" src="assets/images/before_hist_norm.png"/>
							<p class="t-paragraph" style="text-align: center;">Fig. 4: Before normalization</p>
							<div class="divider-1"></div>

					</div>
					<div class="col-md-3" style="text-align: center">
							<img style="width: 200px; height: 200px;" src="assets/images/after_hist_norm.png"/>
							<p class="t-paragraph" style="text-align: center;">Fig. 5: After normalization</p>
							<div class="divider-1"></div>
					</div>
				</div>



				<div class="row">

					<div class="col-md">

							<h4>5. Model/Training</h4>
							<p class="t-paragraph">

								A <b>ResNeXt50</b> has been used for the classification task. We chose this network because it is robust and highly modularized.
								We created a custom balanced train set from the original train set of COVIDx CXR-2 by including all the <b> COVID-19 Positive CXRs (2158)</b> and randomly
								picking the same number of <b> COVID-19 Negative CXRs (2158)</b>.

								The new train set is pretty small comparing to the original one. Therefore, it was crucial to use <b>data augmentation</b> to improve
								the network generalization. The transformations have been applied in the following order: <i>random rotation</i> of 10°, <i>random resize crop</i>,
								<i>brightness/contrast (0.2)</i> and <i>sharpness</i> with a probability of 0.3.
							</p>
							<div class="divider-1"></div>
						</div>

				</div>

				<div class="row">
							<div class="col-md-6" style="text-align: center">
								<img style="width: 400px; height: 400px;" src="assets/images/accuracy.png"/>
								<p class="t-paragraph" style="text-align: center;">Fig. 6: Accuracy</p>
								<div class="divider-1"></div>

							</div>
							<div class="col-md-6" style="text-align: center">
								<img style="width: 400px; height: 400px;" src="assets/images/loss.png"/>
								<p class="t-paragraph" style="text-align: center;">Fig. 7: Loss</p>
								<div class="divider-1"></div>

							</div>

				</div>

				<div class="row">

					<div class="col-md">
							<p class="t-paragraph">
								The model has been trained on 60 epochs on a GTX 1060 (~3 hours) with batch size 32.
								The initial learning rate was equal to 0.001, 0.0005 (epoch 15), 0.00025 (epoch 30) and 0.00012 (epoch 45). The high fluctuations of the validation accuracy is due to the fact that the validation set is smaller than the
								train set. Indeed, the validation set is only <b>9.6%</b>  of the size of the train set. A reasonable ratio would have been equal to  <b>25%</b>. We used the test set of COVIDx CXR-2 as the validation set.
							</p>
							<div class="divider-1"></div>
						</div>

				</div>

					<div class="row">

						<div class="col-md-6">

							<h4>6. Results</h4>
							<p class="t-paragraph">The model reached <b>97%</b> accuracy on the validation set, that is more than satisfying. However, the accuracy is not sufficient to conclude if the
								model can be used to detect SARS-CoV-2 2019 (COVID-19) infection. Indeed, we need to measure the <b>sensitivity</b> and the <b>positive predictive value</b> of each class. For instance,
							we do want to reduce the number of false negative for obvious health reasons. </p>

							<div class="divider-1"></div>
						</div>
						<div class="col-md">

								<h4>7. Score</h4>
									<p class="t-paragraph">
									The score of the challenge to the final test results is based on the weighted sum of the Sensitivity, Positive Predictive Value (PPV), and the Runtime of the model. To be more specific, the final score is as follows:
										<br><br></p>
										<p class="t-paragraph" style="text-align: center;"> <i>Score=6SP+5SN+3PP+2PN-wt</i><p>
										<p class="t-paragraph">
											Where SP and PP refer to the Sensitivity and PPV of the COVID-19 positive class. PN and SN refers to the Sensitivity and PPV of the COVID-19 negative class. t is the runtime of the algorithm and w is a non-negative weight.
										</p>
									<br>
								</p>

							<div class="divider-1"></div>
						</div>
				</div>

				<div class="row">

					<div class="col-md">

							<h4>8. Analyzis</h4>
							<p class="t-paragraph">

								When we tested our very first model on the competition set we discovered that the number of COVID-19 Positive CXRs was very low. 2 were detected positive out of 400, even though the model had 94%
								accuracy and a high score (15.80) on the validation set. As a result, we kept track of the number of positive cases during the training after each epoch.
							</p>
							<div class="divider-1"></div>
					</div>
				</div>
				<div class="row">
							<div class="col-md-6" style="text-align: center">
								<img style="width: 300px; height: 300px;" src="assets/images/score.png"/>
								<p class="t-paragraph" style="text-align: center;">Fig. 8: Before penalization</p>
								<br>

								<img style="width: 300px; height: 300px;" src="assets/images/score_sub_5.png"/>
								<p class="t-paragraph" style="text-align: center;">Fig. 9: After penalization</p>
								<div class="divider-1"></div>



							</div>
							<div class="col-md-6" style="text-align: center">
								<p class="t-paragraph">

									As you can see from the graph <i>Competition (before penalization)</i>, the percentage (percent) of positive cases detected on the competition test oscillates a lot around 20% during the training. <i> Please note that the score is the score of the validation set
									as we did not have access to the labels of the competition set.</i> This behavior revealed that the competition set might contain very difficult images.
								</p>
								<br>
								<p class="t-paragraph">
									Our third submission scored <b>11.81</b> with <b>20%</b> positive cases. Therefore, we had to improve our model to make it detect more true positive cases.
									We saved the weights of our model when the accuracy was high (greater than 95%) and the percentage of positive cases detected greater than 30%.
									<br><br>
									We came up with a new model (training above) that scored <b>13.71</b> with an accuracy of <b>97%</b> on the validation set and
									<b>34%</b> positive cases detected on the competition test. Clearly, positive cases were still missing.
									<br><br>
									We decided to penalize more the false negative cases during the training. As you can see from the graph <i>Competition (after penalization)</i>, the percentage (percent) of positive cases detected on the competition test is higher than before (epochs 20-30). At this point, we got our last model that scored <b>14.44</b> (fifth submission).
									The accuracy on the validation set was lower: <b>93%</b>, but it predicted fewer false negative cases on the competition set. Because the COVID-19 Negative CXRs are randomly selected at each training session, we fine tuned the model multiple times on different train sets.
									<br><br>
									Our final submission is the aggregation of our two previous submissions which scored <b>14.60</b> and ranked us <b>4th place</b>.
								</p>

							</div>



					</div>

				<div class="row">

					<div class="col-md">

							<h4>9. Improvements (phase II)</h4>
							<p class="t-paragraph">
								Here are a non exhaustive list of possible improvements that we did not have time to try and that could be used for Phase II:
									<br>
									- <b>Localized Energy-Based Normalization</b>: efficiently normalize images from different sources, energy decomposition of the images in different bands [3].
									<br>
									- <b>Combine Classification and Lung Segmentation: </b> multi-target training can sometimes lead to better performance (e.g classifier connected to the bottle neck of an U-Net).
									<br>
									- <b>Generative Adversarial Networks: </b> generate more "data", especially positive cases, with GAN.


							</p>
							<div class="divider-1"></div>
					</div>
				</div>

					<div class="row">

					<div class="col-md">

							<h4>10. References</h4>
							<p class="t-paragraph">

								[1] Xie, Saining & Girshick, Ross & Dollar, Piotr & Tu, Z. & He, Kaiming. (2017). Aggregated Residual Transformations for Deep Neural Networks. 5987-5995. 10.1109/CVPR.2017.634. NEURAL NETWORKS:
								<br><br>
								[2] Wang, L., Lin, Z.Q. & Wong, A. COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images. Sci Rep 10, 19549 (2020).
							    <br><br>
								[3] Philipsen, Rick & Maduskar, Pragnya & Hogeweg, Laurens & Melendez, Jaime & Sanchez, Clara & Ginneken, Bram. (2015). Localized Energy-Based Normalization of Medical Images: Application to Chest Radiography. IEEE transactions on medical imaging. 34. 10.1109/TMI.2015.2418031.

							</p>
							<div class="divider-1"></div>
					</div>
				</div>

			</div>

		</section>





		<footer>
			<div class="container" style="background: #e0ecf8;">
				<br>

				<div class="row">

					<div class ="col-md 4"  style="text-align: center;">

						<h5 class="t-skills"> <i class="fa fa-phone"></i> Téléphone </h5>
						<li style="display: inline; color: rgb(78, 75, 75);">
							<p style="margin-bottom: 1px;"> 🇫🇷 +33 7 49 50 52 13 </p>
						</li>
						<li style="display:inline; color: rgb(78, 75, 75);">
							<p > 🇨🇦 +1 (438) 238-6866 </p>
						</li>

					</div>
					<div class ="col-md 4"  style="text-align: center;">
						<h5 class="t-skills"> <i class="fa fa-envelope"></i> Email </h5>
						<li style="display: inline; color: rgb(78, 75, 75);">
							<p > gilles[dot]schneider[dot]imt[at]gmail.com </p>
						</li>
					</div>
				</div>
			</div>
			<br>
		</footer>
			<script src="https://unpkg.com/scrollreveal"></script>
			<script src="app.js"></script>

	</body>



</html>

